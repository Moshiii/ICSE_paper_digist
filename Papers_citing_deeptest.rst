                  DeepXplore: Automated Whitebox Testing of Deep Learning Systems
Kexin et al 2017


white box testing

dataset:
including Udacity self-driving car challenge data, image data
from ImageNet and MNIST, Android malware data from
Drebin, and PDF malware data from Contagio/VirusTotal.

performance: 
The
inputs generated by DeepXplore achieved 34.4% and 33.2%
higher neuron coverage on average than the same number of
randomly picked inputs and adversarial inputs

workflow:

.. image:: img/deepexplore.PNG
   :width: 40pt


DeepGauge: multi-granularity testing criteria for deep learning systems
Lei et al . 2018
whitebox
dataset:
MNIST Imagenet

idea:
 5 types of coverage metrics:
 KMNC NBC SNAC TKNC TKNP

Houdini 
NIPS 2017


-- Chauffeurnet: Learning to drive by imitating the best and synthesizing the worst

DeepConcolic: Testing and Debugging Deep Neural Networks
Youcheng et al 2019

   DeepConcolic is the first tool that implements a concolic testing technique for DNNs

Adversarial Sample Detection for Deep Neural Network through Model Mutation Testing
Jingyi  et al 2019 icse

   In this work, we provide a complementary perspective
   and propose an approach for detecting adversarial samples at
   runtime. The idea is that, given an arbitrary input sample to
   a DNN, to decide at runtime whether it is likely to be an
   adversarial sample or not. If it is, we raise an alarm and report
   that the sample is ‘suspicious’ with certain confidence. Once
   detected, it can be rejected or checked depending on different
   applications. 


Symbolic Execution for Attribution and Attack Synthesis in Neural Networks
Divya et al.  2019 ICSE

   DeepCheck implements techniques for lightweight symbolic
   analysis of DNNs and applies them in the context of image classification to address two challenging problems: 1) identification
   of important pixels (for attribution and adversarial generation);
   and 2) creation of adversarial attacks. 

Formal Security Analysis of Neural Networks using Symbolic Intervals
Shiqi et al 2018 usenix

   In this paper, we present a new direction for formally
   checking security properties of DNNs without using SMT
   solvers. Instead, we leverage interval arithmetic to compute rigorous bounds on the DNN outputs. 

Efficient Formal Safety Analysis of Neural Networks
Shiqi ET AL 2018 NIPS
   
   In this paper, we present a new efficient approach for rigorously checking
   different safety properties of neural networks that significantly outperforms existing
   approaches by multiple orders of magnitude.


Deepmutation: Mutation testing of deep learning systems
lei et al. 2018
   In this paper, we
   propose a mutation testing framework specialized for DL systems
   to measure the quality of test data.


Testing deep neural networks
 Youcheng et al 2019
 
   In this paper, inspired by the MC/DC coverage criterion, we
   propose a family of four novel test criteria that are tailored to structural features
   of DNNs and their semantics.
 
 
DeepRoad: GAN-based metamorphic testing and input validation framework for autonomous driving systems
Mengshi et al 2018

   In this paper, we propose DeepRoad, an unsupervised DNN-based
   framework for automatically testing the consistency of DNN-based
   autonomous driving systems and online validation. 

Tensorfuzz: Debugging neural networks with coverage-guided fuzzing
Augustus et al 2019 

   We introduce testing techniques for neural networks that
   can discover errors occurring only for rare inputs. Specifically, we develop coverage-guided fuzzing (CGF)
   methods for neural networks.

Guiding deep learning system testing using surprise adequacy
Jinhan et al 2019

   We propose a novel test
   adequacy criterion for testing of DL systems, called Surprise
   Adequacy for Deep Learning Systems (SADL), which is based
   on the behaviour of DL systems with respect to their training
   data.

Autonomous cars: Research results, issues, and future challenges

Simulation-based adversarial test generation for autonomous vehicles with machine learning components

Strike (with) a pose: Neural networks are easily fooled by strange poses of familiar objects

## Deeproad: Gan-based metamorphic autonomous driving system testing

Identifying implementation bugs in machine learning based image classifiers using metamorphic testing

Towards practical verification of machine learning: The case of computer vision systems

Dlfuzz: Differential fuzzing testing of deep learning systems
